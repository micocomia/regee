{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.68.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: numpy>=2.0.2 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: sounddevice>=0.5.1 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.5.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sounddevice>=0.5.1->openai) (1.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\karel\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\karel\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.5.1->openai) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_generator.py\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "from typing import List, Dict, Any, Optional\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class QuestionGenerator:\n",
    "    \"\"\"\n",
    "    Generates questions based on document content using LLM.\n",
    "    \"\"\"\n",
    "    def __init__(self, retrieval_system, api_key: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the question generator.\n",
    "        \n",
    "        Args:\n",
    "            retrieval_system: RetrievalSystem for finding relevant document chunks\n",
    "            api_key: OpenAI API key (will try to get from environment if None)\n",
    "        \"\"\"\n",
    "        self.retrieval_system = retrieval_system\n",
    "        \n",
    "        # Use provided API key or get from environment\n",
    "        self.api_key = api_key or os.getenv(\"OPENAI_API_KEY\")\n",
    "        if self.api_key:\n",
    "            openai.api_key = self.api_key\n",
    "        else:\n",
    "            logger.warning(\"No OpenAI API key provided. Question generation will be limited.\")\n",
    "    \n",
    "    def generate_question(self, topics: Optional[List[str]] = None, \n",
    "                          question_type: str = \"multiple-choice\",\n",
    "                          difficulty: str = \"medium\") -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate a question based on document content.\n",
    "        \n",
    "        Args:\n",
    "            topics: Optional list of topics to focus on\n",
    "            question_type: Type of question (multiple-choice or free-text)\n",
    "            difficulty: Difficulty level (easy, medium, hard)\n",
    "            \n",
    "        Returns:\n",
    "            Question data including question text, answer, and options (for MC)\n",
    "        \"\"\"\n",
    "        # Retrieve relevant contexts for the question\n",
    "        # Use a random topic from the provided list if available\n",
    "        topic = random.choice(topics) if topics and len(topics) > 0 else None\n",
    "        \n",
    "        # Retrieve contexts for the chosen topic\n",
    "        contexts = self.retrieval_system.retrieve_for_question_generation(\n",
    "            topic=topic, \n",
    "            num_contexts=3\n",
    "        )\n",
    "        \n",
    "        if not contexts:\n",
    "            # Fallback for no contexts\n",
    "            return self._generate_fallback_question(question_type)\n",
    "        \n",
    "        # Prepare context text for the LLM\n",
    "        context_text = \"\\n\\n\".join([ctx['content'] for ctx in contexts])\n",
    "        \n",
    "        try:\n",
    "            if self.api_key:\n",
    "                return self._generate_with_llm(context_text, question_type, difficulty, topic)\n",
    "            else:\n",
    "                return self._generate_simple_question(context_text, question_type, difficulty)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating question: {str(e)}\")\n",
    "            return self._generate_fallback_question(question_type)\n",
    "    \n",
    "    def _generate_with_llm(self, context: str, question_type: str, \n",
    "                            difficulty: str, topic: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a question using LLM.\"\"\"\n",
    "        # Create a prompt based on question type and difficulty\n",
    "        if question_type == \"multiple-choice\":\n",
    "            prompt = self._create_mc_prompt(context, difficulty, topic)\n",
    "        else:\n",
    "            prompt = self._create_free_text_prompt(context, difficulty, topic)\n",
    "        \n",
    "        # Call the OpenAI API\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert educational assistant creating review questions.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        question_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        try:\n",
    "            # Try to parse structured JSON from response\n",
    "            if \"{\" in question_text and \"}\" in question_text:\n",
    "                json_str = question_text[question_text.find(\"{\"):question_text.rfind(\"}\")+1]\n",
    "                question_data = json.loads(json_str)\n",
    "                \n",
    "                # Add question type to the data\n",
    "                question_data[\"type\"] = question_type\n",
    "                \n",
    "                return question_data\n",
    "            else:\n",
    "                # Manual parsing if no JSON structure found\n",
    "                return self._parse_question_text(question_text, question_type)\n",
    "        except json.JSONDecodeError:\n",
    "            return self._parse_question_text(question_text, question_type)\n",
    "    \n",
    "    def _create_mc_prompt(self, context: str, difficulty: str, topic: Optional[str] = None) -> str:\n",
    "        \"\"\"Create a prompt for multiple-choice question generation.\"\"\"\n",
    "        topic_instruction = f\"about {topic}\" if topic else \"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "        Based on the following context, create a challenging multiple-choice question {topic_instruction}.\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        The difficulty level should be: {difficulty}\n",
    "        \n",
    "        Return your response as a JSON object with these fields:\n",
    "        - question: The question text\n",
    "        - options: Array of 4 possible answers (A, B, C, D)\n",
    "        - answer: The correct option letter (A, B, C, or D)\n",
    "        - explanation: Brief explanation of why the answer is correct\n",
    "        \n",
    "        Make sure the options are clearly distinct and that only one answer is truly correct.\n",
    "        \"\"\"\n",
    "    \n",
    "    def _create_free_text_prompt(self, context: str, difficulty: str, topic: Optional[str] = None) -> str:\n",
    "        \"\"\"Create a prompt for free-text question generation.\"\"\"\n",
    "        topic_instruction = f\"about {topic}\" if topic else \"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "        Based on the following context, create a thoughtful free-text question {topic_instruction} that requires understanding and analysis.\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        The difficulty level should be: {difficulty}\n",
    "        \n",
    "        Return your response as a JSON object with these fields:\n",
    "        - question: The question text\n",
    "        - answer: A model answer to the question\n",
    "        - key_points: 3-5 key points that should be present in a good answer\n",
    "        \n",
    "        The question should be specific enough that it can be answered based on the context, but open-ended enough to allow for some analysis.\n",
    "        \"\"\"\n",
    "    \n",
    "    def _parse_question_text(self, text: str, question_type: str) -> Dict[str, Any]:\n",
    "        \"\"\"Manually parse question text if JSON parsing fails.\"\"\"\n",
    "        lines = text.split('\\n')\n",
    "        question = \"\"\n",
    "        options = []\n",
    "        answer = \"\"\n",
    "        explanation = \"\"\n",
    "        key_points = []\n",
    "        \n",
    "        # Basic parsing for multiple-choice\n",
    "        if question_type == \"multiple-choice\":\n",
    "            # First line is usually the question\n",
    "            question = lines[0].strip()\n",
    "            \n",
    "            # Look for options (A, B, C, D)\n",
    "            for line in lines[1:]:\n",
    "                if line.strip().startswith(('A)', 'B)', 'C)', 'D)', 'A.', 'B.', 'C.', 'D.')):\n",
    "                    option = line.strip()[2:].strip()\n",
    "                    options.append(option)\n",
    "                elif \"answer\" in line.lower() or \"correct\" in line.lower():\n",
    "                    # Try to extract the answer letter\n",
    "                    if \"A\" in line and \"A)\" in text:\n",
    "                        answer = \"A\"\n",
    "                    elif \"B\" in line and \"B)\" in text:\n",
    "                        answer = \"B\"\n",
    "                    elif \"C\" in line and \"C)\" in text:\n",
    "                        answer = \"C\"\n",
    "                    elif \"D\" in line and \"D)\" in text:\n",
    "                        answer = \"D\"\n",
    "                elif \"explanation\" in line.lower():\n",
    "                    explanation = line.replace(\"Explanation:\", \"\").strip()\n",
    "        else:\n",
    "            # Free-text parsing\n",
    "            question = lines[0].strip()\n",
    "            \n",
    "            # Find answer paragraph\n",
    "            answer_idx = -1\n",
    "            for i, line in enumerate(lines):\n",
    "                if \"answer\" in line.lower() or \"response\" in line.lower():\n",
    "                    answer_idx = i\n",
    "                    break\n",
    "            \n",
    "            if answer_idx > 0 and answer_idx < len(lines) - 1:\n",
    "                answer = lines[answer_idx + 1].strip()\n",
    "            \n",
    "            # Try to find key points\n",
    "            for line in lines:\n",
    "                if \"key point\" in line.lower() or \"important\" in line.lower():\n",
    "                    key_point = line.strip()\n",
    "                    if \":\" in key_point:\n",
    "                        key_point = key_point.split(\":\", 1)[1].strip()\n",
    "                    key_points.append(key_point)\n",
    "        \n",
    "        # Create question data\n",
    "        question_data = {\n",
    "            \"type\": question_type,\n",
    "            \"question\": question\n",
    "        }\n",
    "        \n",
    "        if question_type == \"multiple-choice\":\n",
    "            question_data[\"options\"] = options[:4]  # Limit to 4 options\n",
    "            question_data[\"answer\"] = answer\n",
    "            question_data[\"explanation\"] = explanation\n",
    "        else:\n",
    "            question_data[\"answer\"] = answer\n",
    "            question_data[\"key_points\"] = key_points\n",
    "        \n",
    "        return question_data\n",
    "    \n",
    "    def _generate_simple_question(self, context: str, question_type: str, difficulty: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a simple question when no LLM is available.\"\"\"\n",
    "        # Extract sentences from context\n",
    "        sentences = [s.strip() for s in context.split('.') if len(s.strip()) > 20]\n",
    "        \n",
    "        if not sentences:\n",
    "            return self._generate_fallback_question(question_type)\n",
    "        \n",
    "        # Select a random sentence for the question\n",
    "        question_sentence = random.choice(sentences)\n",
    "        \n",
    "        # Create a simple question by asking about the sentence\n",
    "        if question_type == \"multiple-choice\":\n",
    "            # Create a cloze question\n",
    "            words = question_sentence.split()\n",
    "            if len(words) < 5:\n",
    "                return self._generate_fallback_question(question_type)\n",
    "            \n",
    "            # Select a word to remove (not from the beginning or end)\n",
    "            idx = random.randint(2, len(words) - 2)\n",
    "            answer_word = words[idx]\n",
    "            words[idx] = \"______\"\n",
    "            \n",
    "            question = \" \".join(words)\n",
    "            \n",
    "            # Create distractors (other random words from the context)\n",
    "            all_words = context.split()\n",
    "            all_words = [w for w in all_words if len(w) > 3 and w != answer_word]\n",
    "            distractors = random.sample(all_words, min(3, len(all_words)))\n",
    "            \n",
    "            # Ensure we have enough options\n",
    "            while len(distractors) < 3:\n",
    "                distractors.append(\"None of the above\")\n",
    "            \n",
    "            # Create options and shuffle\n",
    "            options = [answer_word] + distractors\n",
    "            random.shuffle(options)\n",
    "            \n",
    "            # Find the correct answer letter\n",
    "            answer_idx = options.index(answer_word)\n",
    "            answer_letter = chr(65 + answer_idx)  # Convert to A, B, C, D\n",
    "            \n",
    "            return {\n",
    "                \"type\": \"multiple-choice\",\n",
    "                \"question\": f\"Complete the following sentence: {question}\",\n",
    "                \"options\": options,\n",
    "                \"answer\": answer_letter,\n",
    "                \"explanation\": f\"The correct word is '{answer_word}' based on the context.\"\n",
    "            }\n",
    "        else:\n",
    "            # Free-text question\n",
    "            return {\n",
    "                \"type\": \"free-text\",\n",
    "                \"question\": f\"Explain the following concept in your own words: {question_sentence}\",\n",
    "                \"answer\": question_sentence,\n",
    "                \"key_points\": [s.strip() for s in sentences[:3] if s != question_sentence]\n",
    "            }\n",
    "    \n",
    "    def _generate_fallback_question(self, question_type: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a fallback question when no context is available.\"\"\"\n",
    "        if question_type == \"multiple-choice\":\n",
    "            return {\n",
    "                \"type\": \"multiple-choice\",\n",
    "                \"question\": \"What is the primary purpose of a retrieval system in a conversational AI?\",\n",
    "                \"options\": [\n",
    "                    \"To generate random responses\",\n",
    "                    \"To find relevant information from a knowledge base\",\n",
    "                    \"To create visual charts and graphs\",\n",
    "                    \"To translate text between languages\"\n",
    "                ],\n",
    "                \"answer\": \"B\",\n",
    "                \"explanation\": \"The primary purpose of a retrieval system is to find and retrieve relevant information from a knowledge base or document store to help answer questions accurately.\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"type\": \"free-text\",\n",
    "                \"question\": \"Explain how a retrieval-augmented generation (RAG) system works and why it's useful for conversational AI?\",\n",
    "                \"answer\": \"A retrieval-augmented generation system combines information retrieval with text generation. It first finds relevant documents or passages from a knowledge base, then uses those as context for generating accurate and informative responses.\",\n",
    "                \"key_points\": [\n",
    "                    \"Combines retrieval and generation\",\n",
    "                    \"Uses vector search to find relevant information\",\n",
    "                    \"Provides context to the language model\",\n",
    "                    \"Improves accuracy of responses\",\n",
    "                    \"Reduces hallucination in AI responses\"\n",
    "                ]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No OpenAI API key provided. Question generation will be limited.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Question: Complete the following sentence: This is a sample ______ about machine learning\n",
      "Options: ['common', 'intelligence.', 'document', 'Machine']\n",
      "Answer: C\n",
      "Explanation: The correct word is 'document' based on the context.\n"
     ]
    }
   ],
   "source": [
    "# Mock a retrieval system for testing \n",
    "class MockRetrievalSystem:\n",
    "    def retrieve_for_question_generation(self, topic=None, num_contexts=3):\n",
    "        # Return some mock contexts for the topic\n",
    "        return [\n",
    "            {\"content\": \"This is a sample document about machine learning.\"},\n",
    "            {\"content\": \"Machine learning is a subfield of artificial intelligence.\"},\n",
    "            {\"content\": \"A common technique in machine learning is supervised learning.\"}\n",
    "        ]\n",
    "\n",
    "# Initialize the QuestionGenerator with the mock retrieval system\n",
    "mock_retrieval_system = MockRetrievalSystem()\n",
    "question_generator = QuestionGenerator(retrieval_system=mock_retrieval_system)\n",
    "\n",
    "# Test the question generation\n",
    "topics = [\"machine learning\", \"artificial intelligence\", \"data science\"]  # Example topics\n",
    "question_data = question_generator.generate_question(topics=topics, question_type=\"multiple-choice\", difficulty=\"medium\")\n",
    "\n",
    "# Display the generated question\n",
    "print(\"Generated Question:\", question_data.get(\"question\"))\n",
    "print(\"Options:\", question_data.get(\"options\"))\n",
    "print(\"Answer:\", question_data.get(\"answer\"))\n",
    "print(\"Explanation:\", question_data.get(\"explanation\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
